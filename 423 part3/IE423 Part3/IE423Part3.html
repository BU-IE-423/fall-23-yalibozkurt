<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=BnIqpcFAcReH0Tw3JLCcnA);.lst-kix_74s2ertaesbo-2>li:before{content:"-  "}.lst-kix_74s2ertaesbo-3>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-4>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-5>li:before{content:"-  "}.lst-kix_c2vcbj6xsyyl-2>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-2}.lst-kix_c2vcbj6xsyyl-8>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-8,lower-roman) ". "}.lst-kix_c2vcbj6xsyyl-7>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-7,lower-latin) ". "}ol.lst-kix_c2vcbj6xsyyl-2.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-2 0}.lst-kix_74s2ertaesbo-6>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-1>li:before{content:"-  "}.lst-kix_74s2ertaesbo-4>li:before{content:"-  "}.lst-kix_74s2ertaesbo-5>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-2>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-3>li:before{content:"-  "}.lst-kix_c2vcbj6xsyyl-2>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-2,lower-roman) ". "}.lst-kix_c2vcbj6xsyyl-4>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-4,lower-latin) ". "}.lst-kix_c2vcbj6xsyyl-3>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-3,decimal) ". "}.lst-kix_c2vcbj6xsyyl-3>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-3}.lst-kix_c2vcbj6xsyyl-6>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-6,decimal) ". "}.lst-kix_74s2ertaesbo-7>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-0>li:before{content:"-  "}.lst-kix_74s2ertaesbo-8>li:before{content:"-  "}.lst-kix_c2vcbj6xsyyl-5>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-5,lower-roman) ". "}ul.lst-kix_wluqao3lyjjh-0{list-style-type:none}ul.lst-kix_wluqao3lyjjh-1{list-style-type:none}ul.lst-kix_wluqao3lyjjh-4{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-5.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-5 0}ul.lst-kix_wluqao3lyjjh-5{list-style-type:none}.lst-kix_c2vcbj6xsyyl-0>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-0}ul.lst-kix_wluqao3lyjjh-2{list-style-type:none}ul.lst-kix_wluqao3lyjjh-3{list-style-type:none}ul.lst-kix_wluqao3lyjjh-8{list-style-type:none}ul.lst-kix_wluqao3lyjjh-6{list-style-type:none}ul.lst-kix_wluqao3lyjjh-7{list-style-type:none}ul.lst-kix_phz8u5mji557-4{list-style-type:none}ul.lst-kix_phz8u5mji557-5{list-style-type:none}ul.lst-kix_phz8u5mji557-6{list-style-type:none}ul.lst-kix_phz8u5mji557-7{list-style-type:none}ul.lst-kix_phz8u5mji557-0{list-style-type:none}ul.lst-kix_phz8u5mji557-1{list-style-type:none}ul.lst-kix_phz8u5mji557-2{list-style-type:none}ul.lst-kix_phz8u5mji557-3{list-style-type:none}ul.lst-kix_phz8u5mji557-8{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-8.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-8 0}ul.lst-kix_v84wlgtvt0xd-3{list-style-type:none}ul.lst-kix_v84wlgtvt0xd-4{list-style-type:none}ul.lst-kix_v84wlgtvt0xd-5{list-style-type:none}ul.lst-kix_v84wlgtvt0xd-6{list-style-type:none}.lst-kix_c2vcbj6xsyyl-5>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-5}ul.lst-kix_v84wlgtvt0xd-0{list-style-type:none}ul.lst-kix_v84wlgtvt0xd-1{list-style-type:none}ul.lst-kix_v84wlgtvt0xd-2{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-1.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-1 0}ul.lst-kix_v84wlgtvt0xd-7{list-style-type:none}ul.lst-kix_v84wlgtvt0xd-8{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-7.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-7 0}.lst-kix_c2vcbj6xsyyl-6>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-6}ul.lst-kix_74s2ertaesbo-0{list-style-type:none}ul.lst-kix_74s2ertaesbo-1{list-style-type:none}ul.lst-kix_74s2ertaesbo-2{list-style-type:none}ul.lst-kix_74s2ertaesbo-3{list-style-type:none}ul.lst-kix_74s2ertaesbo-4{list-style-type:none}ul.lst-kix_74s2ertaesbo-5{list-style-type:none}ul.lst-kix_74s2ertaesbo-6{list-style-type:none}ul.lst-kix_74s2ertaesbo-7{list-style-type:none}ul.lst-kix_74s2ertaesbo-8{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-3{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-2{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-1{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-0{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-7{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-0.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-0 0}ol.lst-kix_c2vcbj6xsyyl-6{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-5{list-style-type:none}ol.lst-kix_c2vcbj6xsyyl-4{list-style-type:none}.lst-kix_wluqao3lyjjh-8>li:before{content:"-  "}.lst-kix_74s2ertaesbo-0>li:before{content:"-  "}.lst-kix_74s2ertaesbo-1>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-6>li:before{content:"-  "}.lst-kix_wluqao3lyjjh-7>li:before{content:"-  "}ul.lst-kix_4krhx05ot8gd-1{list-style-type:none}ul.lst-kix_4krhx05ot8gd-2{list-style-type:none}.lst-kix_4krhx05ot8gd-0>li:before{content:"\0025cf   "}ul.lst-kix_4krhx05ot8gd-3{list-style-type:none}ul.lst-kix_4krhx05ot8gd-4{list-style-type:none}.lst-kix_4krhx05ot8gd-1>li:before{content:"\0025cb   "}ul.lst-kix_4krhx05ot8gd-5{list-style-type:none}ul.lst-kix_4krhx05ot8gd-6{list-style-type:none}.lst-kix_c2vcbj6xsyyl-8>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-8}ul.lst-kix_4krhx05ot8gd-7{list-style-type:none}ul.lst-kix_4krhx05ot8gd-8{list-style-type:none}.lst-kix_phz8u5mji557-6>li:before{content:"\0025cf   "}.lst-kix_4krhx05ot8gd-3>li:before{content:"\0025cf   "}.lst-kix_4krhx05ot8gd-2>li:before{content:"\0025a0   "}.lst-kix_4krhx05ot8gd-4>li:before{content:"\0025cb   "}ol.lst-kix_c2vcbj6xsyyl-8{list-style-type:none}.lst-kix_phz8u5mji557-7>li:before{content:"\0025cb   "}ol.lst-kix_c2vcbj6xsyyl-6.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-6 0}.lst-kix_phz8u5mji557-8>li:before{content:"\0025a0   "}.lst-kix_phz8u5mji557-1>li:before{content:"\0025cb   "}.lst-kix_phz8u5mji557-3>li:before{content:"\0025cf   "}.lst-kix_phz8u5mji557-2>li:before{content:"\0025a0   "}.lst-kix_phz8u5mji557-5>li:before{content:"\0025a0   "}.lst-kix_phz8u5mji557-4>li:before{content:"\0025cb   "}.lst-kix_v84wlgtvt0xd-1>li:before{content:"-  "}.lst-kix_v84wlgtvt0xd-2>li:before{content:"-  "}.lst-kix_v84wlgtvt0xd-0>li:before{content:"-  "}.lst-kix_phz8u5mji557-0>li:before{content:"\0025cf   "}.lst-kix_4krhx05ot8gd-7>li:before{content:"\0025cb   "}.lst-kix_4krhx05ot8gd-6>li:before{content:"\0025cf   "}.lst-kix_4krhx05ot8gd-8>li:before{content:"\0025a0   "}.lst-kix_4krhx05ot8gd-5>li:before{content:"\0025a0   "}ol.lst-kix_c2vcbj6xsyyl-4.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-4 0}.lst-kix_v84wlgtvt0xd-5>li:before{content:"-  "}.lst-kix_v84wlgtvt0xd-3>li:before{content:"-  "}.lst-kix_v84wlgtvt0xd-4>li:before{content:"-  "}ol.lst-kix_c2vcbj6xsyyl-3.start{counter-reset:lst-ctn-kix_c2vcbj6xsyyl-3 0}.lst-kix_v84wlgtvt0xd-6>li:before{content:"-  "}.lst-kix_v84wlgtvt0xd-7>li:before{content:"-  "}.lst-kix_v84wlgtvt0xd-8>li:before{content:"-  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_c2vcbj6xsyyl-1>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-1,lower-latin) ". "}.lst-kix_c2vcbj6xsyyl-7>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-7}.lst-kix_c2vcbj6xsyyl-4>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-4}.lst-kix_c2vcbj6xsyyl-0>li:before{content:"" counter(lst-ctn-kix_c2vcbj6xsyyl-0,decimal) ". "}.lst-kix_c2vcbj6xsyyl-1>li{counter-increment:lst-ctn-kix_c2vcbj6xsyyl-1}ul.lst-kix_4krhx05ot8gd-0{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c16{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:106.5pt;border-top-color:#000000;border-bottom-style:solid}.c15{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:174.8pt;border-top-color:#000000;border-bottom-style:solid}.c21{-webkit-text-decoration-skip:none;color:#000000;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:11pt;font-family:"Arial";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c27{color:#333333;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Arial";font-style:normal}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left;height:11pt}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c1{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:center}.c6{color:#1d2125;text-decoration:none;vertical-align:baseline;font-size:23pt;font-family:"Roboto";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{color:#000000;text-decoration:none;vertical-align:baseline;font-size:23pt;font-family:"Times New Roman";font-style:normal}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c22{border-spacing:0;border-collapse:collapse;margin-right:auto}.c29{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c33{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-align:left}.c23{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c35{font-weight:400;font-size:22pt;font-family:"Times New Roman"}.c20{font-size:15pt;font-family:"Times New Roman";font-weight:400}.c28{font-weight:400;font-size:10pt;font-family:"Arial"}.c30{font-size:18pt;font-family:"Times New Roman";font-weight:400}.c2{font-size:18pt;font-family:"Times New Roman";font-weight:700}.c25{font-weight:400;font-size:12pt;font-family:"Arial"}.c32{font-weight:400;font-size:17pt;font-family:"Times New Roman"}.c26{font-size:23pt;font-family:"Times New Roman"}.c38{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c7{margin-left:36pt;padding-left:0pt}.c24{font-size:19pt;font-family:"Times New Roman"}.c34{font-size:15pt;font-family:"Times New Roman"}.c12{background-color:#ffffff;font-style:italic}.c31{padding:0;margin:0}.c18{orphans:2;widows:2}.c19{height:11pt}.c4{font-weight:700}.c36{height:21pt}.c14{background-color:#ffffff}.c17{background-color:#ff0000}.c37{height:38.2pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c14 c38 doc-content"><p class="c10"><span class="c4 c26">IE 423: QUALITY ENGINEERING</span></p><p class="c10 c19"><span class="c6 c4"></span></p><p class="c10"><span class="c23 c24 c4">Project Part 3</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 283.00px; height: 283.00px;"><img alt="" src="images/image13.png" style="width: 283.00px; height: 283.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10 c19"><span class="c23 c24 c4"></span></p><p class="c10"><span class="c2">Instructor</span><span class="c2">: </span><span class="c23 c30">Mustafa Baydo&#287;an</span></p><p class="c10"><span class="c2">Date of Submission:</span><span class="c20">&nbsp;</span><span class="c30">09.01.2024</span></p><p class="c13"><span class="c23 c32"></span></p><p class="c18 c33"><span class="c4 c34">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;Prepared by:</span><span class="c20 c23">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c13"><span class="c11"></span></p><a id="t.6e4759cda726b93f25ff87dbd07b69b1305be5e0"></a><a id="t.0"></a><table class="c22"><thead><tr class="c36"><td class="c15" colspan="1" rowspan="1"><p class="c29"><span class="c20">&nbsp; &nbsp; &nbsp;&#304;brahim Emre K&ouml;ksal</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c20">2019402171</span></p></td></tr><tr class="c37"><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c20">Yusuf Ali Bozkurt</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c20">2019402021</span></p></td></tr><tr class="c36"><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c20">&#304;dil Zeynep Ceylan</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c20">2020402033</span></p></td></tr></thead></table><p class="c13"><span class="c11"></span></p><p class="c13"><span class="c11"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span class="c1">Introduction</span></p><p class="c5"><span class="c8">What is linen? Why is it important to monitor processing of linens? What are the motivations regarding the use of images and identification of defects in linen manufacturing? </span></p><p class="c0"><span class="c8"></span></p><p class="c5"><span class="c11">Made from the fibers of the flax plant, linen is a textile that is highly valued in the textile industry. Beyond its difficult production process, linen is distinguished by its exceptional properties that have made it a desirable fabric for a variety of purposes. Clothes made of linen are widely valued because of its breathable and absorbent nature and excellent coolness in hot and humid weather. In addition, being a natural heat conductor, linen keeps you warm without causing heat transfer to occur through your skin by retaining the heat in its fibers. Linen is also easy to dye due to its natural fibers ability to retain dye colors better than other materials. Furthermore, linen&#39;s longevity which outperforms that of cotton, as well as its eco-friendliness which is demonstrated by its rapid biodegradability and low water requirements make it a durable and sustainable textile. (Flanagan)</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">These days, the textile industry relies heavily on technology to produce fabrics due to the need for high-quality products and the challenges presented by the quickly shifting economic landscape. Detecting imperfections and developing patterns have become easier with the help of the artificial eye of the computer, resulting in a significant decrease in manufacturing time as well as labor costs.The textile business, in particular manufacturers of ready-to-wear, must ensure that their products are of a high quality to satisfy customer demands and stay ahead of the competition. Under these conditions, reducing production mistakes and improving the overall process performance depend on the integration of new technologies. Due to the widespread usage of linen in clothing, bedding, and home textiles, it is essential to maintain strict quality control in order to satisfy expectations of consumers. Advanced image processing techniques may need to be integrated since small defects may be overlooked by traditional quality control methods. The project&#39;s emphasis on image-based defect recognition acknowledges that automation has the potential to make inspection procedures more efficient. The effort intends to transform the production of linen by utilizing an advanced method for texture analysis and image acquisition, providing a quick and easy process for detecting problems. By reducing the need for human inspection, this creative method not only raises the overall quality of linen products but also increases production efficiency. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">Research indicates that in the fabric industry, imperfect fabric defects account for a substantial 85% of all produced defects. Producer enterprises, recognizing the economic potential in addressing these imperfections, achieve about 45-65% of their earnings from their second quality or lower quality products. This strategic approach not only enhances profitability but also significantly reduces the percentage of mistakes made during the knitting and weaving phases by an impressive 80%. Moreover, the adoption of computer-based defect detection contributes to sustainability efforts by lowering defective production, which otherwise represents up to 5% of textile waste. In this context, the proposed project, leveraging advanced image processing techniques, aims to further enhance defect detection in linen manufacturing, aligning with the industry&#39;s pursuit of efficiency and sustainability. (Ers&ouml;z) </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">In the linen manufacturing industry, the application of control chart perspectives and statistical data analysis demonstrates a dedication to attaining perfection. The project addresses windowed image analysis, control chart techniques, and pixel value distributions in an effort to create an extensive structure for discovering the errors. The project aims to overcome constraints in traditional control charts by identifying the interdependence of pixel values in textured images and developing an effective technique for identifying abnormalities in linen manufacturing. </span></p><p class="c5"><span class="c11">&nbsp;</span></p><p class="c5"><span class="c1">Background Information</span></p><p class="c5"><span class="c8">What has been done in the literature regarding the process monitoring on linen?</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>In a former research paper called &ldquo;NIR Tools for Quality Assessment of Flax Fibre, Yarn and Linen Fabric&rdquo; </span><span class="c11">the application of Near-Infrared (NIR) technology in the European linen industry is explored. Near-Infrared (NIR) technology is a technique for identifying and analyzing different compounds using light in the near-infrared region of the electromagnetic spectrum.This technology is based on the distinct ways that various materials reflect and absorb light. By seeing how particular types of light interact with an object, near-infrared (NIR) technology helps us determine what the object is composed of. In this paper, the focus is on identifying key measurement parameters at different processing stages, ranging from fiber production to weaving, and assessing how NIR analysis can serve as a rapid and objective tool for quality assessment. The overall goal is to reduce production costs at each stage of linen production by leveraging objective measurement standards provided by NIR technology. Potentials of NIR technology are stated as: </span></p><ul class="c31 lst-kix_v84wlgtvt0xd-0 start"><li class="c5 c7 li-bullet-0"><span class="c11">Ability to grade production batches for key quality parameters, leading to enhanced metrology and measurement standards.</span></li><li class="c5 c7 li-bullet-0"><span class="c11">Assessment of input raw materials using NIR calibrations, allowing for quality specification and improved efficiency during mechanical preparation.</span></li><li class="c5 c7 li-bullet-0"><span class="c11">Implementation of a system for predicting yarn performance, with samples analyzed using NIR technology. Ensures consistent fabric quality, and a weaver issues a purchase order only if the test yarn sample satisfies quality thresholds.</span></li></ul><p class="c5"><span>The results indicate that the use of Vis-NIR calibrations as tools has a dramatic impact on measurement standards in the linen industry. (</span><span class="c14">Sharma) </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>Another </span><span>paper titled &quot;A learning based approach for automatic defect detection in the textile industry&quot; addresses the issue of textile defect detection through a machine-learning approach. The method is based on a statistical and multi-resolution modeling of texture images, complemented by naive Bayes classification.The authors offer an innovative approach that applies supervised learning to classify textile textures into defect and non-defect classes based on feature extraction and classification. The approach generates precise signatures for texture description by statistical modeling of multi-scale contourlet image decomposition. The two stages of the defect identification approach are: (1) using a training set to extract reference defect-free signatures; and (2) applying a Bayes classifier to distinguish between </span><span>non-defected</span><span>&nbsp;and defected classes in new images. The algorithm demonstrates the ability to achieve highly accurate defect detection and localization in textile textures while maintaining computational efficiency. Experimental results demonstrate the algorithm&#39;s outperformance compared to recent methods in terms of accuracy and computation time. (Yapi) </span></p><p class="c0"><span class="c11"></span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c1">Approach- Our Proposal</span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span>Our proposed methodology addresses the inherent challenges associated with monitoring image data, particularly in the context of spatial characteristics. </span><span class="c11">The fundamental issue lies in the limitations of traditional control charts, which are designed for one-dimensional time series data and assume independence among observations. However, images represent a class of spatial data, presenting a unique challenge as pixel values are intrinsically correlated, especially in the presence of textures. The task at hand involves developing a control technique that is both effective and sensitive to the spatial dependencies between pixel values in order to identify problematic areas within the image.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>We seek to methodically address the difficulties involved in tracking image data in a spatial context with our proposed methodology. Our proposal includes monitoring</span><span>&nbsp;and controlling multiple correlated variables simultaneously to detect shifts or trends in the joint behavior of the variables. The proposal consists of two consecutive stages. First of these stages is the </span><span>assessment of correlations within the image dataset using advanced spatial statistics methods. Comprehending the interdependencies among pixel values is crucial, particularly when textures are present, as they naturally generate problems with autocorrelation.By examining every row and column of the image, correlation between the axes are proven. The second stage, implementation stage, focuses on selecting an appropriate multivariate control chart that accommodates the reduced set of characteristics and implementing it in the study. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c21">Stage1: Correlations </span></p><p class="c0"><span class="c21"></span></p><p class="c5"><span class="c11">In the initial stage of our proposed methodology, we focus on assessing correlations among the spatial data of images. Spatial statistics, designed for monitoring and controlling data organized in 2D or 3D spaces such as images or maps, are employed for this purpose. Given that our study works on image analysis, spatial autocorrelation statistics become crucial in measuring the autocorrelation among neighboring observations within the image. This step allows us to capture and understand the interdependence of pixel values, a key factor in addressing the complexities associated with monitoring image data.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">In our correlation assessment stage, we optimize the calculation of autocorrelations through the implementation of a system known as lag. This method deviates from the traditional approach of evaluating autocorrelations for all possible combinations of rows by introducing a strategically defined lag. A lag refers to the observation of a variable at a previous time or space in the context of time series analysis and spatial data. It is an essential concept in autocorrelation, which quantifies the degree of similarity between a given variable&#39;s current value and its past values at various time points or spatial locations. In the context of our methodology, a lag represents a specified number of positions at which the autocorrelation is computed. By adopting the lag system, we transition to a more efficient process, assessing autocorrelations row by row. This enables us to focus on specific relationships between a given row and its lagged counterparts.This approach significantly reduces computational time and resource requirements, making it a pragmatic choice for our correlation analysis. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">By understanding the interdependence and spatial relationships revealed by autocorrelations between rows, we identify key characteristics that contribute significantly to the variance within the dataset.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">In our correlation assessment stage, it is crucial to acknowledge, however, that the inherent correlation in manufacturing processes is driven by inertial elements. Particularly, when the sampling interval is small relative to these forces, observations on the process exhibit temporal correlations. Moreover, achieving low defect rates and ensuring high-quality outcomes often necessitate 100% inspection, leading to correlated inspection data. This correlation is a natural consequence of thorough inspection practices. With advancements in sensing techniques and increased computer capacity, the importance of 100% inspection has grown, especially in the context of image measurement. The enhanced capabilities in sensing and computing empower more robust inspection methodologies, contributing to the correlation observed in the data. (3) </span></p><p class="c0"><span class="c11"></span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span class="c21">Stage 2: Appropriate Multivariate Control Chart </span></p><p class="c0"><span class="c21"></span></p><p class="c5"><span>In the third and final stage of our proposed methodology, we address the importance of selecting an appropriate multivariate control chart. Independent monitoring of two quality characteristics through separate univariate charts may lead to misleading interpretations. A point observation, falling within the control limits of both univariate charts individually due to joint probability, might exhibit unusual behavior when considered simultaneously. The use of two independent x-bar charts, in this context, introduces the potential for Type 1 errors, where anomalies are overlooked in the joint analysis. To avoid such pitfalls, our methodology emphasizes the need for a carefully chosen multivariate control chart that enables comprehensive and accurate monitoring of correlated variables, thus providing a more robust and nuanced approach to defect detection in spatial data.</span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span class="c11">In our experimentation, we obtained varying detection counts for different images in both the multivariate chart and the univariate chart. This observation reinforces the essential need for multivariate analysis, emphasizing the nuanced nature of defect detection across diverse images. This discrepancy in detection counts between the multivariate and univariate charts underscores the significance of adopting a multivariate approach. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>Among the three well-known multivariate control charts&mdash;Chi-square, </span><img src="images/image1.png"><span>Hotelling, and Multivariate EWMA&mdash;we opt for the Chi-Square Control chart in our proposal. The Chi-Square distribution is a good option for defect detection scenarios when the observed imperfections are discrete in nature and it is frequently employed in statistical hypothesis testing and quality control when working with categorical data or counts. Chi-Square control charts are particularly sensitive to changes in counts, making them effective for scenarios where the focus is on monitoring the occurrence of defects in different categories. In contrast, T2 Hotelling and Multivariate EWMA are often applied when dealing with continuous data. The Chi-Square control chart enables the examination of runs or other nonrandom patterns by maintaining the time sequence of data. This feature, which enables a nuanced investigation of patterns or abnormalities over time, is useful in defect identification settings. The chart&#39;s capacity to express the &quot;state&quot; of the process as a single number makes it easier to interpret, which is especially useful when handling several quality characteristics at once. </span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span class="c1">Results </span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span class="c21">A Baseline Defect Detection Approach from a Statistical Data Analysis Perspective </span></p><p class="c0"><span class="c21"></span></p><p class="c5"><span class="c11">This first method is for executing a quality control procedure on the linen images based on the pixel value distribution of the whole image and within the &nbsp;patches of the image. </span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span>As the first step we transformed the color images provided to us into grayscale images which can be considered as a matrix of size 512x512 and each matrix entry represents the intensity/brightness level for that pixel. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">As the second step, to estimate the pixel value distribution of our image, a histogram of pixel values is drawn. We observed that the distribution of our pixel values resembles a normal distribution. This can be seen in the image below where a normal distribution curve is fit to the histogram of pixel values. </span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 376.50px; height: 280.91px;"><img alt="" src="images/image15.jpg" style="width: 376.50px; height: 280.91px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">Assuming that the pixel values are following a normal distribution, the parameters of that distribution are estimated as follows: </span></p><ul class="c31 lst-kix_wluqao3lyjjh-0 start"><li class="c5 c7 li-bullet-0"><span class="c11">Mean: 168.46</span></li><li class="c5 c7 li-bullet-0"><span>Variance:</span><span class="c11">16.008</span></li></ul><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">Then the pixels with intensity values that are out of the 0.001 probability limits are identified and the value of those pixels are changed to zero which corresponds to black color in the image.The distribution graph with lower and upper bound is as follows:</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 582.00px; height: 208.00px;"><img alt="" src="images/image9.jpg" style="width: 624.00px; height: 208.00px; margin-left: -42.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c11">&nbsp;The original image and the new image after this modification is shown below: </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 309.33px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 309.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c11">When the statistical defect detection approach is applied to the whole image we identified 23 defects in total and changed the color of those 23 pixels to black. When the two images are compared there is not an obvious difference that can be easily detected with the eye since only 23 pixels out of 262144 pixels are changed to black. This result &nbsp;implies that our original image was close to perfect with only 23 defects that can be detected when statistical approach is applied. However, in order to draw a conclusion about the original quality of our image, we need to test the reliability of this statistical method and the validity of the result by comparing the result obtained with different methods. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>As the second part of this method, </span><span class="c11">the same operations that we performed on the images up to this point are applied on the patches of images. In the patch-based defect detection approach, a window size of 51x51 is defined for processing image patches. The algorithm systematically slides through the image, utilizing a specified step size of 10 for efficient coverage. For each patch, a defect detection and correction function is applied, involving the estimation of mean and standard deviation parameters for a normal distribution. The lower and upper bounds are then calculated to encompass 99.9% of the distribution, allowing identification of pixels beyond the 0.001 probability limits. Defective coordinates are marked, and their values are set to zero in the original image. This process is iteratively carried out for all patches using the sliding window mechanism. The main objective is to locate anomalies and fix them locally so that local structures can be preserved. For visual assessment, the final images&mdash;both before and after correction&mdash;are shown. This technique allows for improved detection of defects and repair in situations when local structures are essential to preserving image quality.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>The original and new image are shown below: </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 298.67px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 298.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c11">The number of total defective pixels identified with this method is 766. The substantial difference in the number of identified defective pixels between the patch-based method (766 defects) and the whole-image-based method (23 defects) suggests that the patch-based approach is more sensitive to localized anomalies. Due to its smaller window size and systematic sliding across the image, the patch-based approach permits a more thorough analysis of local structures and pixel value variations. On the other hand, the whole-image-based method considers the pixel value distribution through the entire image, potentially smoothing out localized variations.This method may be less sensitive to small-scale irregularities, leading to a lower count of identified defects. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">The patch-based method works particularly well for images with complex local structures and subtle variances. This approach works effectively for images with significant local complexities, as fine-grained defect detection is important in these kinds of settings. However, given that it offers a thorough perspective, the whole-image-based approach might work better for images with more uniform features. When a wider view is sufficient and the objective is to capture larger-scale flaws while possibly missing small anomalies inside certain localized regions, this approach might be preferred. Considering that precision in linen manufacturing is crucial for maintaining the exceptional quality and standards associated with linen products, the patch-based defect detection method would be preferred. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c21">A Simple Defect Detection Approach from a Control Chart Perspective </span></p><p class="c0"><span class="c21"></span></p><p class="c5"><span>This second </span><span class="c11">proposal is used to identify pixel values that are beyond the control limits by examining each row and column in the matrix, assuming that the pixel distribution is the same both horizontally and vertically.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>First, t</span><span>he method for rows systematically assesses each row of the input image to detect and rectify out-of-control pixel values. Initializing a copy of the original image and a variable to track changed pixels, the code iterates through each row. Extracting pixel values for each row, the </span><span>find_out_of_control_pixels</span><span class="c11">&nbsp;function is utilized, incorporating a threshold parameter set to 3. This threshold determines which pixels are deemed out of control, with the default criterion being an absolute deviation from the mean exceeding three times the standard deviation. Detected out-of-control pixels are then set to zero in the modified image, and the count of changed pixels is updated. The final outcome includes a modified image with corrected row-wise defects, alongside the total count of changed pixels. Adjusting the threshold parameter allows for customization based on image characteristics and desired sensitivity for defect detection.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c11">The original and new image are as follows:</span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image8.jpg" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span>The number of pixels changed to zero in rows is 81. In this instance, the number of defects detected offers a numerical representation of the extent of irregularities in the row-wise pixel values. </span><span class="c11">It specifically targets variations along the horizontal axis, providing insights into potential defects that impact specific rows. Considering the number of defects identified, it can be concluded that this method offers a balanced perspective between the global overview of the whole image method and the localized sensitivity of the patch-based method and maintains a level of specificity that mitigates the risk of false positives.</span></p><p class="c5"><span class="c11">As the second step, the same operations are performed on the columns of the image and the following results are obtained: </span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image3.jpg" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span>The number of pixels changed to zero in columns is 48. When compared to the 81 defectives identified in rows, th</span><span>e higher count of defective pixels in rows compared to columns suggests that there are variations or anomalies that predominantly affect the horizontal distribution of pixel values, thus specific patterns or irregularities along the horizontal axis of the image. It could be attributed to factors such as texture variations, image artifacts, or specific features present in the linen material. On the other hand, the lower count of defective pixels in columns suggests a relatively more stable distribution in the vertical direction. Observing the images above, we can see that there is an obvious defect in the image, which is the horizontal line passing through the image that disrupts the steady structure of the image. Implying that the horizontal abnormalities caused a higher number of defectives in row-wise comparisons. </span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c21">Our Proposal</span></p><p class="c0"><span class="c21"></span></p><p class="c5"><span class="c11">The first step of our proposal was to assess the spatial correlations within the image dataset using advanced spatial statistics methods. The method that we used to perform this step is described above in the &ldquo;Approach-Our Proposal&rdquo; section. As a result, we plotted the autocorrelations between the rows as follows:</span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 516.73px; height: 258.36px;"><img alt="" src="images/image2.png" style="width: 516.73px; height: 258.36px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c11">As the second step, the chi-square control chart is chosen as the appropriate multivariate control chart method due to the reasons that are explained in the &ldquo;Approach-Our Proposal&rdquo; section above. When we applied our proposal to our image first, we obtained the following output. The first one is the original image and the second one is the processed one:</span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3 c18"><span class="c4">Image 0070(Our Image)</span></p><p class="c5"><span class="c23 c25">&nbsp;</span></p><p class="c0"><span class="c23 c25"></span></p><p class="c5"><span class="c23 c25">Then we evaluated our proposal in 5 alternative images chosen randomly from the provided linen images. The original and processed images are provided below:</span></p><p class="c0"><span class="c23 c25"></span></p><p class="c0"><span class="c23 c25"></span></p><p class="c0"><span class="c23 c25"></span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3 c18"><span class="c4">Image 0019</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.50px; height: 289.25px;"><img alt="" src="images/image10.png" style="width: 578.50px; height: 289.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span class="c4">Image 0068</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span class="c4">Image 0078</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span class="c4">Image 0094</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span class="c4">Image 0170</span></p><p class="c0"><span class="c11"></span></p><p class="c0"><span class="c11"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c5"><span class="c1">Conclusion and Future Work</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span>T</span><span>he Chi-Square control chart is a key component of our methodology that we use to identify defects. The Chi-Square distribution&#39;s fit for count-based monitoring and its compatibility with the discrete nature of linen image flaws serve as the foundation for this choice. In addition to supporting count data, the Chi-Square control chart maintains the data&#39;s temporal sequence, enabling the study of runs or nonrandom patterns. Moreover, the chart&#39;s capacity to summarize the &quot;state&quot; of the process in terms of a single statistic is consistent with our focus on readability and simplicity. T</span><span class="c11">he use of the Chi-Square control chart complements our methodology by providing an effective means to monitor and control counts of defects in linen images. </span></p><p class="c0"><span class="c11 c17"></span></p><p class="c5"><span>Several possible extensions can be taken into consideration in order to enhance the linen image detection method. Firstly, to dynamically modify the defect detection threshold according to local image properties, adaptive thresholding algorithms could be applied. This can enhance the approach&#39;s adaptability across various linen images and lessen the effects of varying lighting conditions. Secondly, implementing a real-time monitoring system that allows for immediate feedback and intervention is possible. This can be achieved by leveraging edge computing or cloud-based solutions to process and analyze images in real-time, facilitating timely corrective actions.</span></p><p class="c0"><span class="c11"></span></p><p class="c5"><span class="c1">References</span></p><ol class="c31 lst-kix_c2vcbj6xsyyl-0 start" start="1"><li class="c5 c7 li-bullet-0"><span class="c11">Flanagan, Lauren. &ldquo;Design 101: Everything You Need to Know about Linen Fabric.&rdquo; The Spruce, The Spruce, 3 Dec. 2023, www.thespruce.com/definition-of-linen-fabric-1976785. </span></li><li class="c5 c7 li-bullet-0"><span class="c11">Ers&ouml;z T., Zahoor H., Ers&ouml;z F. &ldquo;Fabric And Production Defect Detection In The Apparel Industry Using Data Mining Algorithms&rdquo;, Int. J. of 3D Printing Tech. Dig. Ind., 5(3): 742-757, (2021). </span></li><li class="c5 c7 li-bullet-0"><span class="c14">Guo, Weihong, et al. &quot;A Data-Driven Diagnostic System Utilizing Manufacturing Data Mining and Analytics.&quot; </span><span class="c12">SAE International Journal of Materials and Manufacturing</span><span class="c14">, vol. 10, no. 3, July 2017. </span><span class="c12">Gale Academic OneFile</span><span class="c11 c14">. </span></li><li class="c5 c7 li-bullet-0"><span class="c14">Sharma, Shekhar. (2005). NIR TOOLS FOR QUALITY ASSESSMENT OF FLAX </span><span class="c14">FIBRE</span><span class="c11 c14">, YARN AND LINEN FABRIC. In Focus. 29. 10-11. </span></li><li class="c5 c7 li-bullet-0"><span class="c14">Yapi, Mejri, Mohand Sa&iuml;d Allili, Nadia Baaziz, A Learning-Based Approach for Automatic Defect Detection in Textile Images,IFAC-PapersOnLine,Volume 48, Issue 3,2015,Pages 2423-2428,ISSN 2405-8963.</span></li></ol><p class="c0"><span class="c14 c27"></span></p><p class="c0"><span class="c11"></span></p><p class="c0"><span class="c11"></span></p></body></html>